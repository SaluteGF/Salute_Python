<div align='center' >

# 编码方式

</div>

> [程序练习](https://github.com/Nicolas-gaofeng/Salute_Python/blob/main/code/summary/coding.py)

## 1. 字符编码说明

字符编码这个知识点其实只是涉及到一行代码，但是它非常重要，据不完全统计，现在软件30%的损失都是由于乱码问题所导致的，这个问题是最容易被大家所忽视的，因为使用的时候只是一行代码的问题，但是它的里面包含很多的知识，大部分人更加倾向于直接掌握结果，而不考虑它内部的知识，这就导致了一旦遇到字符编码的乱码问题，就会手足无措。你之前可能看过一些相关的介绍，正确与否我们先不做评论，在这篇文章中，我们会对字符编码进行全方位的介绍。字符编码的特点是理论非常多，而结论非常少，但是如果不知道理论，结论可能永远也无法理解，而且以后遇到字符编码问题就会不知所措。

## 2. 编码种类

### 2.1 ASCII

最初版本的密码本：所有的英文字母，数字，特殊字符。

ASCII编码用单字节表示字符，最高位固定为0，故最多只能表示128个字符，当编程只涉及到英文字符或数字时，不涉及中文字符时，可以使用ASCII编码。

ASCII最左边为0，为当时设计师预留的一位，设计师认为七位足可以表示英文+数字+特殊字符

### 2.2 unicode

万国码，将所有国家的语言文字都写入这个密码本

在文本文件中，看到的所有字符，包括中文，都需要在计算机中存储，而计算机只能存储0和1这样的二进制位，所以需要一种方法，将字符映射成数字，然后将数字转化为二进制位存储在计算机中。针对字符和数字的映射的问题，产生了unicode编码。

unicode将世界上的所有字符映射为唯一的数字。unicode数字并不是直接就可以转化为二进制存储，比如假设中文字符‘中’映射为数字1（00000001），‘国’映射为数字2（00000010），由于汉字很多，单字节并不能表示完所有的汉字，故可能会有汉字的unicode数字为258（00000001 00000010），假设为‘京’，现在在字符串中碰到存储为00000001 00000010的二进制串，不能区分出其实际代表的是“中国”还是“京”。

### 2.3 UTF-8

最少用8位表示一个字符

和GB系列不同，UTF-8可以将全世界所有的unicode数字表示出来。`UTF-8兼容ASCII编码，不兼容GB系列编码`，因此，若文本中UTF-8和GB系列编码混用，会出现乱码问题。UTF-8对于每个字符的存储，用最高二进制位开始连续1的个数表示字的长度，最高位为0表示单字节，用来兼容ASCII字符，为110表示双字节，非字符首字节的字节都以10开始，如下表格所示。例如：字符‘中’的unicode编码为2D4E(00101101 01001110),用UTF-8存储的二进制为E4B8AD(11100100 10111000 10101101 )，存储在计算机中的首字节为1110开头，表示此字符占三个字节，去掉开始字节表示长度的1110和其余字节开头的10，可以得到01001110 00101101(4E2D)，可以看到和unicode数字刚好相反，是因为是大端存储方式，高字节存储在内存中的低地址端，反过来即为unicode编码。

### 2.4 GBK

国标，只包含中文，英文（英文，数字，特殊字符）

GB(GuoBiao)为国标，GBK(GuoBiao Kuozhan)表示国标扩展。GB2312兼容ASCII编码，对于ASCII可以表示的字符，如英文字符‘A’、‘B’等，在GB2312中的编码和ASCII编码一致，占一个字节，对于ASCII不能表示的字符，GB2312用两个字节表示，且最高位不为0，以防和ASCII字符冲突。例如：‘A’在GB2312中存储的字节十六进制为41，在ASCII中也是41，中文字符‘中’在GB2312中存储的两个字节十六进制为D6D0，最高位为1不为0。

GB2312只有6763个汉字，而汉字特别多。GBK属于GB2312的扩展，增加了很多汉字，同时兼容GB2312，同样用两个字节表示非ASCII字符。

##  3. 字节码

Pyc文件：C 是 compiled编译过的意思

1. 浏览程序目录会发现一个 pycache 的目录

2. 目录下会有一个 .cpython-35.pyc 文件，cpython-35 表示 Python 解释器的版本

3. 这个 pyc 文件是由 Python解释器将 模块的源码转换为字节码

4. Python 这样保存字节码是作为一种启动速度的优化

**字节码**

- Python在解释源程序时是分成两个步骤的
- 1. 首先处理源代码，编译生成一个二进制字节码
  2. 再对字节码进行处理，才会生成 CPU 能够识别的机器码
- 有了模块的字节码文件之后，下一次运行程序时，如果在上次保存字节码之后没有修改过源代码，Python 将会加载 .pyc 文件并跳过编译这个步骤
- 当 Python 重编译时，它会自动检查源文件和字节码文件的时间戳
- 如果你又修改了源代码，下次程序运行时，字节码将自动重新创建

## 4. 文件头

Python 2.x 默认使用 `ASCII` 编码格式
Python 3.x 默认使用 `UTF-8` 编码格式

注意：既然是文件头，那么自然是要放在文件顶部，这也是开发规范的一些细节

- 通常使用以下代码指定解释器

```python
#!/usr/bin/env python  
```

- 在 Python 2.x 文件的第一行增加以下代码指定文件字符编码，解释器会以 `utf-8` 编码来处理 python 文件

```python
# *-* coding:utf8 *-*
```

这方式是官方推荐使用的！

- 也可以使用

```python
# coding=utf8
```

如果每次写代码我们都自己去写的话有点浪费时间，我们可以自己先在Pycharm上面配置好，以后每次新建一个文件自动就会添加文件头。MacOS系统的用户可以按照先点击Pycharm左上角按照：Pycharm--Preferences--Editor--File and Code Templates--Python Script 的顺序找到一块空白的区域，把以下代码粘贴进去，Windows系统的用户可以按照：File--Settings--Editor--File and Code Templates--Python Script，执行同样的操作。注意：作者那一行代码可以改成你自己的名字。

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : ${DATE} ${TIME}
# @Author  : Albert  
# @File    : ${NAME}.py
```



## 5. 乱码问题的产生与解决

### 5.1 乱码问题的成因



内存中的编码都是Unicode，如果忽略硬盘，在内存中随便写什么编码都不会出现乱码，但是因为硬盘的存在就会出现由内存向硬盘保存的时候你要指定一个字符编码，比如说是GBK，这时就是由Unicode转化成GBK，当把这个硬盘文件重新在内存读取的时候你也要告诉计算机按照GBK编码来读取，它才会对应的把数据由GBK编码反解成Unicode编码写入到内存。如果你在这时告诉你计算机用ASCII的标准来反解数据，那么就无法反解出原来保存的数据内容，计算机懵圈了，呈现给你的就是它懵圈后的结果。

### 5.2 保证不乱码的方案

保证不出现乱码问题其实结论就只有一个：文件用什么编码保存的，就用什么编码读取，注意：我们能控制的只是文件由内存保存到硬盘的编码。

编写python程序时，为避免不同类型字符串混用出现编解码异常，要把编码和解码操作放在程序的最外围来做，程序的核心逻辑统一使用unicode字符类型。
